{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87545125-52c5-41d0-a880-bc4ac8ce0fea",
   "metadata": {},
   "source": [
    "# Pre-Process AutoRPT\n",
    "In this notebook, I will pre-process the AutoRPT data so that we can experiment with traditional ML models and neural networks.\n",
    "\n",
    "Each code block below is explained based on what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dbea244-55b2-4d81-9fa9-752899ccb3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbd1f8b8-84e3-4a13-98f6-a32db4c5e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRPTPreprocessor:\n",
    "    \"\"\"\n",
    "    Preprocessor for AutoRPT dataset - converts timestamps to frame-level labels\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_root, frame_shift_ms=10, target_sr=16000):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.frame_shift_ms = frame_shift_ms\n",
    "        self.frame_shift_samples = int(target_sr * frame_shift_ms / 1000)  # 160 samples at 16kHz\n",
    "        self.target_sr = target_sr\n",
    "        \n",
    "        # Storage for processed data\n",
    "        self.file_pairs = []  # (audio_file, annotation_files)\n",
    "        self.processed_data = []\n",
    "        \n",
    "    def scan_and_match_files(self):\n",
    "        \"\"\"\n",
    "        Scan dataset and create audio-annotation file pairs\n",
    "        \"\"\"\n",
    "        print(\"üîç Scanning and matching files...\")\n",
    "        \n",
    "        # Get all files\n",
    "        audio_files = list(self.data_root.rglob(\"*.wav\"))\n",
    "        annotation_files = list(self.data_root.rglob(\"*_annotations.csv\"))\n",
    "        \n",
    "        print(f\"Found {len(audio_files)} audio files, {len(annotation_files)} annotation files\")\n",
    "        \n",
    "        # Group annotation files by audio basename\n",
    "        audio_to_annotations = defaultdict(list)\n",
    "        \n",
    "        for ann_file in annotation_files:\n",
    "            # Extract basename: f1arrlp5_annotations.csv -> f1arrlp5\n",
    "            basename = ann_file.name.replace('_annotations.csv', '')\n",
    "            audio_to_annotations[basename].append(ann_file)\n",
    "        \n",
    "        # Match with audio files\n",
    "        for audio_file in audio_files:\n",
    "            basename = audio_file.stem\n",
    "            if basename in audio_to_annotations:\n",
    "                annotations = audio_to_annotations[basename]\n",
    "                self.file_pairs.append((audio_file, annotations))\n",
    "                print(f\"‚úÖ Matched {basename}: 1 audio + {len(annotations)} annotations\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è No annotations found for {basename}\")\n",
    "        \n",
    "        print(f\"\\nüìä Final matching: {len(self.file_pairs)} complete sets\")\n",
    "        return len(self.file_pairs)\n",
    "    \n",
    "    def timestamps_to_frame_labels(self, timestamps, audio_duration, tolerance_ms=50):\n",
    "        \"\"\"\n",
    "        Convert timestamp list to frame-level binary labels\n",
    "        \n",
    "        Args:\n",
    "            timestamps: List of event timestamps (in seconds)\n",
    "            audio_duration: Total audio duration (seconds)\n",
    "            tolerance_ms: Tolerance window around each timestamp (milliseconds)\n",
    "        \n",
    "        Returns:\n",
    "            Binary array of frame labels\n",
    "        \"\"\"\n",
    "        # Calculate total frames\n",
    "        total_frames = int(audio_duration * 1000 / self.frame_shift_ms)\n",
    "        frame_labels = np.zeros(total_frames, dtype=np.int8)\n",
    "        \n",
    "        # Convert timestamps to frame indices with tolerance window\n",
    "        tolerance_frames = int(tolerance_ms / self.frame_shift_ms)\n",
    "        \n",
    "        for timestamp in timestamps:\n",
    "            if pd.isna(timestamp):\n",
    "                continue\n",
    "                \n",
    "            # Convert timestamp to frame index\n",
    "            frame_idx = int(timestamp * 1000 / self.frame_shift_ms)\n",
    "            \n",
    "            # Mark frames within tolerance window\n",
    "            start_frame = max(0, frame_idx - tolerance_frames)\n",
    "            end_frame = min(total_frames, frame_idx + tolerance_frames + 1)\n",
    "            \n",
    "            frame_labels[start_frame:end_frame] = 1\n",
    "            \n",
    "        return frame_labels\n",
    "    \n",
    "    def process_annotation_pair(self, annotation_files, audio_duration):\n",
    "        \"\"\"\n",
    "        Process the two annotation files for one audio file\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with aggregated labels from both annotators\n",
    "        \"\"\"\n",
    "        all_prominence_events = []\n",
    "        all_boundary_events = []\n",
    "        \n",
    "        annotator_data = []\n",
    "        \n",
    "        for i, ann_file in enumerate(annotation_files):\n",
    "            df = pd.read_csv(ann_file)\n",
    "            \n",
    "            # Extract events (non-NaN timestamps)\n",
    "            prominence_events = df['Prominence'].dropna().tolist()\n",
    "            boundary_events = df['Boundary'].dropna().tolist()\n",
    "            \n",
    "            all_prominence_events.extend(prominence_events)\n",
    "            all_boundary_events.extend(boundary_events)\n",
    "            \n",
    "            # Store individual annotator data\n",
    "            annotator_data.append({\n",
    "                'annotator_id': i,\n",
    "                'prominence_events': prominence_events,\n",
    "                'boundary_events': boundary_events,\n",
    "                'num_prominence': len(prominence_events),\n",
    "                'num_boundary': len(boundary_events)\n",
    "            })\n",
    "        \n",
    "        # Convert to frame labels\n",
    "        prominence_labels = self.timestamps_to_frame_labels(all_prominence_events, audio_duration)\n",
    "        boundary_labels = self.timestamps_to_frame_labels(all_boundary_events, audio_duration)\n",
    "        \n",
    "        return {\n",
    "            'prominence_labels': prominence_labels,\n",
    "            'boundary_labels': boundary_labels,\n",
    "            'prominence_events': all_prominence_events,\n",
    "            'boundary_events': all_boundary_events,\n",
    "            'annotator_data': annotator_data,\n",
    "            'num_annotators': len(annotation_files)\n",
    "        }\n",
    "    \n",
    "    def extract_basic_features(self, audio_path):\n",
    "        \"\"\"\n",
    "        Extract basic prosodic features from audio\n",
    "        \"\"\"\n",
    "        # Load audio\n",
    "        y, sr = librosa.load(audio_path, sr=self.target_sr)\n",
    "        \n",
    "        # Extract features at frame level\n",
    "        frame_length = int(sr * 0.025)  # 25ms window\n",
    "        hop_length = self.frame_shift_samples  # 10ms hop\n",
    "        \n",
    "        # F0 (pitch)\n",
    "        f0 = librosa.yin(y, fmin=50, fmax=400, sr=sr, \n",
    "                        frame_length=frame_length, hop_length=hop_length)\n",
    "        \n",
    "        # Energy/Intensity  \n",
    "        energy = librosa.feature.rms(y=y, frame_length=frame_length, \n",
    "                                   hop_length=hop_length)[0]\n",
    "        \n",
    "        # Spectral features\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr, \n",
    "                                                              hop_length=hop_length)[0]\n",
    "        \n",
    "        # MFCCs (first 13)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, \n",
    "                                   hop_length=hop_length)\n",
    "        \n",
    "        # Stack features\n",
    "        features = np.vstack([\n",
    "            f0.reshape(1, -1),\n",
    "            energy.reshape(1, -1), \n",
    "            spectral_centroids.reshape(1, -1),\n",
    "            mfccs\n",
    "        ])  # Shape: (16, n_frames)\n",
    "        \n",
    "        return features.T  # Shape: (n_frames, 16)\n",
    "    \n",
    "    def process_single_file(self, audio_file, annotation_files):\n",
    "        \"\"\"\n",
    "        Process one audio file with its annotation files\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"Processing {audio_file.name}...\")\n",
    "            \n",
    "            # Get audio info\n",
    "            audio_info = sf.info(audio_file)\n",
    "            audio_duration = audio_info.duration\n",
    "            \n",
    "            # Process annotations\n",
    "            annotation_data = self.process_annotation_pair(annotation_files, audio_duration)\n",
    "            \n",
    "            # Extract audio features\n",
    "            features = self.extract_basic_features(audio_file)\n",
    "            \n",
    "            # Ensure label and feature alignment\n",
    "            n_feature_frames = features.shape[0]\n",
    "            n_label_frames = len(annotation_data['prominence_labels'])\n",
    "            \n",
    "            # Truncate to minimum length (handle small misalignments)\n",
    "            min_frames = min(n_feature_frames, n_label_frames)\n",
    "            \n",
    "            features = features[:min_frames]\n",
    "            prominence_labels = annotation_data['prominence_labels'][:min_frames]\n",
    "            boundary_labels = annotation_data['boundary_labels'][:min_frames]\n",
    "            \n",
    "            return {\n",
    "                'file_id': audio_file.stem,\n",
    "                'audio_path': str(audio_file),\n",
    "                'audio_duration': audio_duration,\n",
    "                'features': features,\n",
    "                'prominence_labels': prominence_labels,\n",
    "                'boundary_labels': boundary_labels,\n",
    "                'n_frames': min_frames,\n",
    "                'sample_rate': audio_info.samplerate,\n",
    "                'annotation_data': annotation_data\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {audio_file.name}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def process_all_files(self, max_files=None):\n",
    "        \"\"\"\n",
    "        Process all matched files\n",
    "        \"\"\"\n",
    "        if not self.file_pairs:\n",
    "            print(\"‚ùå No file pairs found. Run scan_and_match_files() first.\")\n",
    "            return\n",
    "            \n",
    "        file_pairs_to_process = self.file_pairs[:max_files] if max_files else self.file_pairs\n",
    "        \n",
    "        print(f\"\\nüöÄ Processing {len(file_pairs_to_process)} file pairs...\")\n",
    "        \n",
    "        for i, (audio_file, annotation_files) in enumerate(file_pairs_to_process):\n",
    "            result = self.process_single_file(audio_file, annotation_files)\n",
    "            \n",
    "            if result is not None:\n",
    "                self.processed_data.append(result)\n",
    "                \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"   Processed {i + 1}/{len(file_pairs_to_process)} files...\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Successfully processed {len(self.processed_data)} files\")\n",
    "        \n",
    "    def get_dataset_statistics(self):\n",
    "        \"\"\"\n",
    "        Calculate dataset statistics\n",
    "        \"\"\"\n",
    "        if not self.processed_data:\n",
    "            print(\"‚ùå No processed data available\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\nüìä Dataset Statistics:\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        total_frames = sum(d['n_frames'] for d in self.processed_data)\n",
    "        total_prominence = sum(d['prominence_labels'].sum() for d in self.processed_data)\n",
    "        total_boundary = sum(d['boundary_labels'].sum() for d in self.processed_data)\n",
    "        total_duration = sum(d['audio_duration'] for d in self.processed_data)\n",
    "        \n",
    "        print(f\"Total files: {len(self.processed_data)}\")\n",
    "        print(f\"Total duration: {total_duration/60:.1f} minutes\")\n",
    "        print(f\"Total frames: {total_frames:,}\")\n",
    "        print(f\"Frame resolution: {self.frame_shift_ms}ms\")\n",
    "        \n",
    "        print(f\"\\nLabel Statistics:\")\n",
    "        print(f\"  Prominence events: {total_prominence:,} frames ({100*total_prominence/total_frames:.2f}%)\")\n",
    "        print(f\"  Boundary events: {total_boundary:,} frames ({100*total_boundary/total_frames:.2f}%)\")\n",
    "        \n",
    "        # Feature statistics\n",
    "        all_features = np.vstack([d['features'] for d in self.processed_data])\n",
    "        print(f\"\\nFeature Statistics:\")\n",
    "        print(f\"  Feature dimensions: {all_features.shape[1]}\")\n",
    "        print(f\"  Feature matrix shape: {all_features.shape}\")\n",
    "        \n",
    "        # Class balance\n",
    "        prominence_ratio = total_prominence / total_frames\n",
    "        boundary_ratio = total_boundary / total_frames\n",
    "        \n",
    "        print(f\"\\nClass Balance Assessment:\")\n",
    "        if prominence_ratio < 0.05:\n",
    "            print(f\"  ‚ö†Ô∏è Prominence highly imbalanced ({prominence_ratio:.3f})\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ Prominence reasonably balanced ({prominence_ratio:.3f})\")\n",
    "            \n",
    "        if boundary_ratio < 0.05:\n",
    "            print(f\"  ‚ö†Ô∏è Boundary highly imbalanced ({boundary_ratio:.3f})\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ Boundary reasonably balanced ({boundary_ratio:.3f})\")\n",
    "    \n",
    "    def create_train_val_test_splits(self, train_ratio=0.7, val_ratio=0.15, random_state=42):\n",
    "        \"\"\"\n",
    "        Create train/validation/test splits at the file level\n",
    "        \"\"\"\n",
    "        if not self.processed_data:\n",
    "            print(\"‚ùå No processed data available\")\n",
    "            return None\n",
    "            \n",
    "        # Split at file level to avoid data leakage\n",
    "        file_indices = list(range(len(self.processed_data)))\n",
    "        \n",
    "        # First split: train vs (val + test)\n",
    "        train_idx, temp_idx = train_test_split(\n",
    "            file_indices, \n",
    "            train_size=train_ratio, \n",
    "            random_state=random_state,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        # Second split: val vs test\n",
    "        val_size = val_ratio / (1 - train_ratio)\n",
    "        val_idx, test_idx = train_test_split(\n",
    "            temp_idx,\n",
    "            train_size=val_size,\n",
    "            random_state=random_state,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        splits = {\n",
    "            'train': [self.processed_data[i] for i in train_idx],\n",
    "            'val': [self.processed_data[i] for i in val_idx],\n",
    "            'test': [self.processed_data[i] for i in test_idx]\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nDataset Splits Created:\")\n",
    "        print(f\"  Train: {len(splits['train'])} files\")\n",
    "        print(f\"  Validation: {len(splits['val'])} files\") \n",
    "        print(f\"  Test: {len(splits['test'])} files\")\n",
    "        \n",
    "        return splits\n",
    "    \n",
    "    def save_processed_data(self, output_path=\"autorpt_processed.pkl\"):\n",
    "        \"\"\"\n",
    "        Save processed data to disk\n",
    "        \"\"\"\n",
    "        output_path = Path(output_path)\n",
    "        \n",
    "        save_data = {\n",
    "            'processed_data': self.processed_data,\n",
    "            'preprocessing_config': {\n",
    "                'frame_shift_ms': self.frame_shift_ms,\n",
    "                'target_sr': self.target_sr,\n",
    "                'frame_shift_samples': self.frame_shift_samples\n",
    "            },\n",
    "            'file_pairs': [(str(audio), [str(ann) for ann in anns]) for audio, anns in self.file_pairs]\n",
    "        }\n",
    "        \n",
    "        with open(output_path, 'wb') as f:\n",
    "            pickle.dump(save_data, f)\n",
    "            \n",
    "        print(f\"Processed data saved to {output_path}\")\n",
    "        print(f\"   File size: {output_path.stat().st_size / (1024*1024):.1f} MB\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main preprocessing pipeline\n",
    "    \"\"\"\n",
    "    print(\"AutoRPT Data Preprocessing Pipeline\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize preprocessor\n",
    "    data_root = \"/Users/hasancan/desktop/prosody/AutoRPT_Data\"\n",
    "    preprocessor = AutoRPTPreprocessor(data_root)\n",
    "    \n",
    "    # Step 1: Scan and match files\n",
    "    num_pairs = preprocessor.scan_and_match_files()\n",
    "    \n",
    "    if num_pairs == 0:\n",
    "        print(\"‚ùå No file pairs found. Check data directory.\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Process files (start with a subset for testing)\n",
    "    print(f\"\\nüöÄ Processing files...\")\n",
    "    preprocessor.process_all_files()\n",
    "    \n",
    "    # Step 3: Get statistics\n",
    "    preprocessor.get_dataset_statistics()\n",
    "    \n",
    "    # Step 4: Create splits\n",
    "    splits = preprocessor.create_train_val_test_splits()\n",
    "    \n",
    "    # Step 5: Save processed data\n",
    "    preprocessor.save_processed_data(\"autorpt_processed_subset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d375a057-d183-4b50-9e5b-4994f6520076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéµ AutoRPT Data Preprocessing Pipeline\n",
      "==================================================\n",
      "üîç Scanning and matching files...\n",
      "Found 142 audio files, 284 annotation files\n",
      "‚úÖ Matched f1arrlp7: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1arrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1arrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1arrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1arrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1arrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1arrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1atrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1atrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1atrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1atrlp7: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1atrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1atrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1ajrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1ajrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1ajrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1ajrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1ajrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1ajrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1aprlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1aprlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched f1aprlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1brrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1brrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1brrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1brrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1brrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1brrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1brrlp7: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1btrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1btrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1btrlp7: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1btrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1btrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1btrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1btrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1bjrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1bjrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1bjrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1bjrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1bjrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1bjrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1bprlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1bprlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1bprlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched m1bprlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2brrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2brrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2brrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2brrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2brrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2brrlp7: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2brrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2btrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2btrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2btrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2btrlp7: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2btrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2btrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2btrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2bjrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2bjrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2bjrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2bjrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2bjrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2bjrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2bprlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2bprlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2bprlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched m2bprlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2brrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2brrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2brrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2brrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2brrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2brrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2brrlp7: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2btrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2btrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2btrlp7: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2btrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2btrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2btrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2btrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2bjrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2bjrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2bjrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2bjrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2bjrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2bjrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2bprlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2bprlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2bprlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched f2bprlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3brrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3brrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3brrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3brrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3brrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3brrlp7: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3brrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3btrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3btrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3btrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3btrlp7: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3btrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3btrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3btrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3bjrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3bjrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3bjrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3bjrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3bjrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3bjrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3bprlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3bprlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3bprlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched m3bprlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3arrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3arrlp7: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3arrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3arrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3arrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3arrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3arrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3atrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3atrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3atrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3atrlp7: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3atrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3atrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3atrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3ajrlp4: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3ajrlp5: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3ajrlp6: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3ajrlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3ajrlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3ajrlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3aprlp1: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3aprlp3: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3aprlp2: 1 audio + 2 annotations\n",
      "‚úÖ Matched f3aprlp4: 1 audio + 2 annotations\n",
      "\n",
      "üìä Final matching: 142 complete sets\n",
      "\n",
      "üöÄ Processing files...\n",
      "\n",
      "üöÄ Processing 142 file pairs...\n",
      "Processing f1arrlp7.wav...\n",
      "Processing f1arrlp6.wav...\n",
      "Processing f1arrlp4.wav...\n",
      "Processing f1arrlp5.wav...\n",
      "Processing f1arrlp1.wav...\n",
      "Processing f1arrlp2.wav...\n",
      "Processing f1arrlp3.wav...\n",
      "Processing f1atrlp3.wav...\n",
      "Processing f1atrlp2.wav...\n",
      "Processing f1atrlp6.wav...\n",
      "   Processed 10/142 files...\n",
      "Processing f1atrlp7.wav...\n",
      "Processing f1atrlp5.wav...\n",
      "Processing f1atrlp4.wav...\n",
      "Processing f1ajrlp5.wav...\n",
      "Processing f1ajrlp4.wav...\n",
      "Processing f1ajrlp6.wav...\n",
      "Processing f1ajrlp3.wav...\n",
      "Processing f1ajrlp2.wav...\n",
      "Processing f1ajrlp1.wav...\n",
      "Processing f1aprlp2.wav...\n",
      "   Processed 20/142 files...\n",
      "Processing f1aprlp3.wav...\n",
      "Processing f1aprlp4.wav...\n",
      "Processing m1brrlp3.wav...\n",
      "Processing m1brrlp2.wav...\n",
      "Processing m1brrlp1.wav...\n",
      "Processing m1brrlp5.wav...\n",
      "Processing m1brrlp4.wav...\n",
      "Processing m1brrlp6.wav...\n",
      "Processing m1brrlp7.wav...\n",
      "Processing m1btrlp4.wav...\n",
      "   Processed 30/142 files...\n",
      "Processing m1btrlp5.wav...\n",
      "Processing m1btrlp7.wav...\n",
      "Processing m1btrlp6.wav...\n",
      "Processing m1btrlp2.wav...\n",
      "Processing m1btrlp3.wav...\n",
      "Processing m1btrlp1.wav...\n",
      "Processing m1bjrlp1.wav...\n",
      "Processing m1bjrlp2.wav...\n",
      "Processing m1bjrlp3.wav...\n",
      "Processing m1bjrlp6.wav...\n",
      "   Processed 40/142 files...\n",
      "Processing m1bjrlp4.wav...\n",
      "Processing m1bjrlp5.wav...\n",
      "Processing m1bprlp4.wav...\n",
      "Processing m1bprlp3.wav...\n",
      "Processing m1bprlp2.wav...\n",
      "Processing m1bprlp1.wav...\n",
      "Processing m2brrlp2.wav...\n",
      "Processing m2brrlp3.wav...\n",
      "Processing m2brrlp1.wav...\n",
      "Processing m2brrlp4.wav...\n",
      "   Processed 50/142 files...\n",
      "Processing m2brrlp5.wav...\n",
      "Processing m2brrlp7.wav...\n",
      "Processing m2brrlp6.wav...\n",
      "Processing m2btrlp5.wav...\n",
      "Processing m2btrlp4.wav...\n",
      "Processing m2btrlp6.wav...\n",
      "Processing m2btrlp7.wav...\n",
      "Processing m2btrlp3.wav...\n",
      "Processing m2btrlp2.wav...\n",
      "Processing m2btrlp1.wav...\n",
      "   Processed 60/142 files...\n",
      "Processing m2bjrlp1.wav...\n",
      "Processing m2bjrlp3.wav...\n",
      "Processing m2bjrlp2.wav...\n",
      "Processing m2bjrlp6.wav...\n",
      "Processing m2bjrlp5.wav...\n",
      "Processing m2bjrlp4.wav...\n",
      "Processing m2bprlp4.wav...\n",
      "Processing m2bprlp2.wav...\n",
      "Processing m2bprlp3.wav...\n",
      "Processing m2bprlp1.wav...\n",
      "   Processed 70/142 files...\n",
      "Processing f2brrlp3.wav...\n",
      "Processing f2brrlp2.wav...\n",
      "Processing f2brrlp1.wav...\n",
      "Processing f2brrlp5.wav...\n",
      "Processing f2brrlp4.wav...\n",
      "Processing f2brrlp6.wav...\n",
      "Processing f2brrlp7.wav...\n",
      "Processing f2btrlp4.wav...\n",
      "Processing f2btrlp5.wav...\n",
      "Processing f2btrlp7.wav...\n",
      "   Processed 80/142 files...\n",
      "Processing f2btrlp6.wav...\n",
      "Processing f2btrlp2.wav...\n",
      "Processing f2btrlp3.wav...\n",
      "Processing f2btrlp1.wav...\n",
      "Processing f2bjrlp1.wav...\n",
      "Processing f2bjrlp2.wav...\n",
      "Processing f2bjrlp3.wav...\n",
      "Processing f2bjrlp6.wav...\n",
      "Processing f2bjrlp4.wav...\n",
      "Processing f2bjrlp5.wav...\n",
      "   Processed 90/142 files...\n",
      "Processing f2bprlp4.wav...\n",
      "Processing f2bprlp3.wav...\n",
      "Processing f2bprlp2.wav...\n",
      "Processing f2bprlp1.wav...\n",
      "Processing m3brrlp2.wav...\n",
      "Processing m3brrlp3.wav...\n",
      "Processing m3brrlp1.wav...\n",
      "Processing m3brrlp4.wav...\n",
      "Processing m3brrlp5.wav...\n",
      "Processing m3brrlp7.wav...\n",
      "   Processed 100/142 files...\n",
      "Processing m3brrlp6.wav...\n",
      "Processing m3btrlp5.wav...\n",
      "Processing m3btrlp4.wav...\n",
      "Processing m3btrlp6.wav...\n",
      "Processing m3btrlp7.wav...\n",
      "Processing m3btrlp3.wav...\n",
      "Processing m3btrlp2.wav...\n",
      "Processing m3btrlp1.wav...\n",
      "Processing m3bjrlp1.wav...\n",
      "Processing m3bjrlp3.wav...\n",
      "   Processed 110/142 files...\n",
      "Processing m3bjrlp2.wav...\n",
      "Processing m3bjrlp6.wav...\n",
      "Processing m3bjrlp5.wav...\n",
      "Processing m3bjrlp4.wav...\n",
      "Processing m3bprlp4.wav...\n",
      "Processing m3bprlp2.wav...\n",
      "Processing m3bprlp3.wav...\n",
      "Processing m3bprlp1.wav...\n",
      "Processing f3arrlp6.wav...\n",
      "Processing f3arrlp7.wav...\n",
      "   Processed 120/142 files...\n",
      "Processing f3arrlp5.wav...\n",
      "Processing f3arrlp4.wav...\n",
      "Processing f3arrlp1.wav...\n",
      "Processing f3arrlp3.wav...\n",
      "Processing f3arrlp2.wav...\n",
      "Processing f3atrlp1.wav...\n",
      "Processing f3atrlp2.wav...\n",
      "Processing f3atrlp3.wav...\n",
      "Processing f3atrlp7.wav...\n",
      "Processing f3atrlp6.wav...\n",
      "   Processed 130/142 files...\n",
      "Processing f3atrlp4.wav...\n",
      "Processing f3atrlp5.wav...\n",
      "Processing f3ajrlp4.wav...\n",
      "Processing f3ajrlp5.wav...\n",
      "Processing f3ajrlp6.wav...\n",
      "Processing f3ajrlp2.wav...\n",
      "Processing f3ajrlp3.wav...\n",
      "Processing f3ajrlp1.wav...\n",
      "Processing f3aprlp1.wav...\n",
      "Processing f3aprlp3.wav...\n",
      "   Processed 140/142 files...\n",
      "Processing f3aprlp2.wav...\n",
      "Processing f3aprlp4.wav...\n",
      "\n",
      "Successfully processed 142 files\n",
      "\n",
      "Dataset Statistics:\n",
      "========================================\n",
      "Total files: 142\n",
      "Total duration: 70.0 minutes\n",
      "Total frames: 420,045\n",
      "Frame resolution: 10ms\n",
      "\n",
      "Label Statistics:\n",
      "  Prominence events: 73,541 frames (17.51%)\n",
      "  Boundary events: 22,589 frames (5.38%)\n",
      "\n",
      "Feature Statistics:\n",
      "  Feature dimensions: 16\n",
      "  Feature matrix shape: (420045, 16)\n",
      "\n",
      "Class Balance Assessment:\n",
      "Prominence reasonably balanced (0.175)\n",
      "Boundary reasonably balanced (0.054)\n",
      "\n",
      "Dataset Splits Created:\n",
      "  Train: 99 files\n",
      "  Validation: 21 files\n",
      "  Test: 22 files\n",
      "Processed data saved to autorpt_processed_subset.pkl\n",
      "   File size: 53.3 MB\n"
     ]
    }
   ],
   "source": [
    "# TO RUN THE PREPROCESSING:\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45abe2bb-cc0a-49ef-8e14-96c50fdd4c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FULL AutoRPT dataset...\n",
      "Loaded 142 processed files\n",
      "Total frames: 420,045\n"
     ]
    }
   ],
   "source": [
    "# Load full processed data\n",
    "def load_full_dataset():\n",
    "    print(\"Loading FULL AutoRPT dataset...\")\n",
    "    \n",
    "    with open(\"autorpt_processed_subset.pkl\", 'rb') as f:  # Note: still named \"subset\" but contains all 142 files\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    processed_data = data['processed_data']\n",
    "    config = data['preprocessing_config']\n",
    "    \n",
    "    print(f\"Loaded {len(processed_data)} processed files\")\n",
    "    print(f\"Total frames: {sum(len(d['prominence_labels']) for d in processed_data):,}\")\n",
    "    \n",
    "    return processed_data, config\n",
    "\n",
    "# Load and check the full dataset\n",
    "processed_data, config = load_full_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
